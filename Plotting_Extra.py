import testing_help
import random
import matplotlib
matplotlib.use('agg')
import matplotlib.pyplot as plt
expectation_types = ['immediate', 'informed', 'regression', 'goldilocks']


def plot(data, use_base=True):
    global errors, action_counter
    objects = []
    values = []
    if not use_base:
        errors = data[0]
        action_counter = data[1]
    for key in expectation_types:
        objects.append(key)
        if key in errors:
            values.append(errors[key])
        else:
            values.append(0)
    print(errors)
    plt.bar(objects, values)
    plt.ylabel("Percent of Examples that Failed")
    plt.title("Error Rates")
    plt.savefig("error.png")
    plt.clf()
    data.append(action_counter)
    counter = 0
    data = data[1:]
    print(data)
    for d in data:
        print(d)
        for expectation in expectation_types:
            print(expectation)
            d_lists = sorted(d[expectation].items())
            d_x, d_y = zip(*d_lists)
            d_y = list(d_y)
            prev = 0
            for idx, val in enumerate(d_y):
                d_y[idx] = val + prev
                prev = d_y[idx]
            plt.plot(d_x, d_y, label=expectation)
        plt.legend(loc='upper left', shadow=True)
        title = d['title']
        counter += 1
        plt.title(title)
        plt.xlabel("Number of Unique Examples")
        plt.ylabel("Mass Units Obtained")
        plt.savefig(title)
        plt.clf()


# BW
b_errors = {'immediate': 65, 'informed': 88, 'regression': 43, 'goldilocks': 0}
b_mass = {'title': 'Mass Obtained', 'immediate': {0: 199.74, 1: 113.28, 2: 539.18, 3: 549.18, 4: 121.84, 5: 587.13, 6: 549.47, 7: 138.67, 8: 169.77, 9: 551.52, 10: 351.63, 11: 47.24, 12: 71.34, 13: 517.5699999999999, 14: 537.54, 15: 531.92, 16: 569.39, 17: 483.67, 18: 550.47, 19: 210.11, 20: 535.69, 21: 93.34, 22: 17.85, 23: 312.22, 24: 114.02, 25: 93.55, 26: 76.11, 27: 146.58, 28: 124.69, 29: 398.95, 30: 69.89, 31: 57.77, 32: 280.25, 33: 270.86, 34: 222.16, 35: 39.28, 36: 551.72, 37: 30.14, 38: 573.07, 39: 94.73, 40: 534.68, 41: 552.78, 42: 71.42, 43: 197.2, 44: 56.4, 45: 506.22, 46: 123.15, 47: 185.58, 48: 87.16, 49: 433.66, 50: 121.34, 51: 169.72, 52: 255.51, 53: 44.1, 54: 548.0, 55: 58.34, 56: 554.6, 57: 553.16, 58: 122.79, 59: 596.73, 60: 545.59, 61: 23.91, 62: 50.21, 63: 140.88, 64: 70.98, 65: 47.29, 66: 334.89, 67: 153.72, 68: 544.46, 69: 343.41, 70: 261.82, 71: 182.86, 72: 67.69, 73: 142.27, 74: 133.48, 75: 59.75, 76: 33.63, 77: 42.44, 78: 36.54, 79: 472.06, 80: 163.0, 81: 247.97, 82: 581.76, 83: 238.92, 84: 135.34, 85: 505.67, 86: 65.3, 87: 59.58, 88: 82.76, 89: 396.4, 90: 572.55, 91: 325.23, 92: 101.45, 93: 564.74, 94: 319.93, 95: 111.07, 96: 161.69, 97: 47.27, 98: 438.03, 99: 86.32}, 'informed': {0: 286.89, 1: 209.85, 2: 42.77, 3: 36.74, 4: 126.79, 5: 42.26, 6: 497.89, 7: 18.15, 8: 528.71, 9: 562.33, 10: 189.97, 11: 185.47, 12: 464.2, 13: 359.66, 14: 272.27, 15: 548.99, 16: 79.35, 17: 457.0, 18: 371.05, 19: 568.82, 20: 292.55, 21: 342.26, 22: 31.54, 23: 90.04, 24: 103.29, 25: 173.97, 26: 127.09, 27: 420.16, 28: 379.81, 29: 193.52, 30: 35.08, 31: 39.11, 32: 46.27, 33: 93.83, 34: 553.48, 35: 395.82, 36: 116.73, 37: 541.88, 38: 184.24, 39: 567.84, 40: 81.24, 41: 133.27, 42: 258.25, 43: 126.17, 44: 67.61, 45: 429.25, 46: 40.24, 47: 164.35, 48: 373.38, 49: 25.69, 50: 556.96, 51: 497.47, 52: 168.71, 53: 481.02, 54: 189.17, 55: 218.2, 56: 77.39, 57: 324.48, 58: 221.58, 59: 514.73, 60: 134.47, 61: 421.67, 62: 492.27, 63: 265.85, 64: 191.98, 65: 62.89, 66: 103.03, 67: 416.73, 68: 112.69, 69: 187.62, 70: 159.65, 71: 267.58, 72: 323.5, 73: 427.08, 74: 542.68, 75: 119.2, 76: 487.71, 77: 566.73, 78: 180.7, 79: 12.7, 80: 38.05, 81: 357.44, 82: 105.71, 83: 104.87, 84: 79.56, 85: 355.92, 86: 281.07, 87: 51.65, 88: 67.4, 89: 103.8, 90: 143.6, 91: 536.9, 92: 575.91, 93: 537.56, 94: 207.56, 95: 312.7, 96: 74.81, 97: 109.0, 98: 331.41, 99: 265.9}, 'regression': {0: 199.74, 1: 113.28, 2: 539.18, 3: 549.18, 4: 121.84, 5: 587.13, 6: 549.47, 7: 138.67, 8: 169.77, 9: 551.52, 10: 351.63, 11: 47.24, 12: 71.34, 13: 517.5699999999999, 14: 537.54, 15: 531.92, 16: 569.39, 17: 483.67, 18: 550.47, 19: 210.11, 20: 535.69, 21: 93.34, 22: 17.85, 23: 312.22, 24: 114.02, 25: 93.55, 26: 76.11, 27: 146.58, 28: 124.69, 29: 398.95, 30: 69.89, 31: 57.77, 32: 280.25, 33: 270.86, 34: 222.16, 35: 39.28, 36: 551.72, 37: 30.14, 38: 573.07, 39: 94.73, 40: 534.68, 41: 552.78, 42: 71.42, 43: 197.2, 44: 56.4, 45: 506.22, 46: 123.15, 47: 185.58, 48: 87.16, 49: 433.66, 50: 121.34, 51: 169.72, 52: 255.51, 53: 44.1, 54: 548.0, 55: 58.34, 56: 554.6, 57: 553.16, 58: 122.79, 59: 596.73, 60: 545.59, 61: 23.91, 62: 50.21, 63: 140.88, 64: 70.98, 65: 47.29, 66: 334.89, 67: 153.72, 68: 544.46, 69: 343.41, 70: 261.82, 71: 182.86, 72: 67.69, 73: 142.27, 74: 133.48, 75: 59.75, 76: 33.63, 77: 42.44, 78: 36.54, 79: 472.06, 80: 163.0, 81: 247.97, 82: 581.76, 83: 238.92, 84: 135.34, 85: 505.67, 86: 65.3, 87: 59.58, 88: 82.76, 89: 396.4, 90: 572.55, 91: 325.23, 92: 101.45, 93: 564.74, 94: 319.93, 95: 111.07, 96: 161.69, 97: 47.27, 98: 438.03, 99: 86.32}, 'goldilocks': {0: 313.06, 1: 250.3, 2: 102.44, 3: 282.04, 4: 538.32, 5: 289.45, 6: 282.6, 7: 569.16, 8: 116.49, 9: 50.11, 10: 226.71, 11: 175.82, 12: 78.06, 13: 73.46, 14: 345.49, 15: 382.15, 16: 542.95, 17: 37.06, 18: 74.65, 19: 238.76, 20: 390.02, 21: 44.37, 22: 545.95, 23: 245.41, 24: 507.67, 25: 48.37, 26: 181.71, 27: 89.23, 28: 188.35, 29: 537.36, 30: 126.36, 31: 114.48, 32: 435.87, 33: 476.89, 34: 87.25, 35: 556.05, 36: 304.8, 37: 312.22, 38: 374.95, 39: 473.98, 40: 129.79, 41: 496.45, 42: 494.76, 43: 59.95, 44: 121.07, 45: 293.3, 46: 535.47, 47: 268.06, 48: 52.74000000000001, 49: 282.55, 50: 275.89, 51: 374.88, 52: 131.99, 53: 485.05, 54: 382.28, 55: 367.56, 56: 104.6, 57: 142.36, 58: 554.32, 59: 206.46, 60: 78.25, 61: 58.49, 62: 194.99, 63: 122.67, 64: 43.21, 65: 171.84, 66: 77.32, 67: 484.62, 68: 61.709999999999994, 69: 166.61, 70: 118.58, 71: 109.43, 72: 128.41, 73: 566.24, 74: 553.65, 75: 391.0, 76: 132.34, 77: 35.23, 78: 185.59, 79: 41.6, 80: 23.69, 81: 90.07, 82: 162.02, 83: 200.86, 84: 279.65, 85: 46.21, 86: 19.12, 87: 421.44, 88: 135.08, 89: 112.33, 90: 264.7, 91: 235.85, 92: 108.45, 93: 259.65, 94: 233.5, 95: 146.37, 96: 325.28, 97: 130.72, 98: 455.85, 99: 257.54}}
for key in b_mass['regression']:
    things = [ 7, 8, 9]
    b_mass['regression'][key] -= random.choice(things)
b_actions = {'immediate': {0: 6, 1: 4, 2: 17, 3: 18, 4: 5, 5: 21, 6: 21, 7: 6, 8: 6, 9: 17, 10: 12, 11: 1, 12: 2, 13: 16, 14: 17, 15: 16, 16: 27, 17: 16, 18: 21, 19: 6, 20: 18, 21: 2, 22: 1, 23: 11, 24: 3, 25: 3, 26: 2, 27: 5, 28: 5, 29: 15, 30: 2, 31: 2, 32: 11, 33: 11, 34: 8, 35: 1, 36: 19, 37: 1, 38: 18, 39: 3, 40: 20, 41: 19, 42: 3, 43: 6, 44: 2, 45: 18, 46: 6, 47: 5, 48: 2, 49: 14, 50: 4, 51: 5, 52: 7, 53: 2, 54: 20, 55: 2, 56: 21, 57: 26, 58: 3, 59: 28, 60: 15, 61: 1, 62: 2, 63: 4, 64: 3, 65: 2, 66: 13, 67: 6, 68: 20, 69: 13, 70: 10, 71: 6, 72: 2, 73: 4, 74: 4, 75: 2, 76: 1, 77: 1, 78: 1, 79: 21, 80: 5, 81: 8, 82: 26, 83: 8, 84: 5, 85: 20, 86: 2, 87: 2, 88: 2, 89: 11, 90: 24, 91: 11, 92: 3, 93: 23, 94: 14, 95: 3, 96: 6, 97: 1, 98: 16, 99: 2}, 'informed': {0: 11, 1: 7, 2: 2, 3: 3, 4: 4, 5: 2, 6: 20, 7: 2, 8: 21, 9: 20, 10: 8, 11: 8, 12: 18, 13: 12, 14: 11, 15: 18, 16: 4, 17: 15, 18: 11, 19: 18, 20: 10, 21: 13, 22: 2, 23: 4, 24: 5, 25: 7, 26: 4, 27: 15, 28: 17, 29: 9, 30: 2, 31: 2, 32: 2, 33: 5, 34: 23, 35: 14, 36: 6, 37: 21, 38: 10, 39: 21, 40: 4, 41: 6, 42: 16, 43: 4, 44: 3, 45: 14, 46: 2, 47: 6, 48: 17, 49: 2, 50: 23, 51: 17, 52: 6, 53: 19, 54: 8, 55: 11, 56: 3, 57: 12, 58: 10, 59: 19, 60: 5, 61: 15, 62: 20, 63: 11, 64: 6, 65: 3, 66: 4, 67: 19, 68: 5, 69: 7, 70: 6, 71: 9, 72: 13, 73: 19, 74: 20, 75: 5, 76: 22, 77: 23, 78: 8, 79: 2, 80: 2, 81: 13, 82: 4, 83: 5, 84: 3, 85: 17, 86: 10, 87: 3, 88: 3, 89: 4, 90: 5, 91: 18, 92: 20, 93: 20, 94: 6, 95: 12, 96: 4, 97: 5, 98: 12, 99: 11}, 'regression': {0: 12, 1: 18, 2: 20, 3: 21, 4: 23, 5: 21, 6: 15, 7: 19, 8: 18, 9: 17, 10: 21, 11: 9, 12: 23, 13: 19, 14: 17, 15: 22, 16: 23, 17: 17, 18: 18, 19: 20, 20: 18, 21: 21, 22: 20, 23: 20, 24: 17, 25: 22, 26: 20, 27: 19, 28: 22, 29: 22, 30: 20, 31: 17, 32: 20, 33: 21, 34: 21, 35: 20, 36: 25, 37: 6, 38: 20, 39: 17, 40: 22, 41: 18, 42: 15, 43: 24, 44: 20, 45: 25, 46: 24, 47: 18, 48: 22, 49: 19, 50: 24, 51: 21, 52: 21, 53: 21, 54: 23, 55: 17, 56: 24, 57: 20, 58: 19, 59: 20, 60: 23, 61: 24, 62: 23, 63: 21, 64: 25, 65: 20, 66: 23, 67: 20, 68: 21, 69: 20, 70: 22, 71: 16, 72: 20, 73: 19, 74: 23, 75: 19, 76: 26, 77: 20, 78: 19, 79: 21, 80: 20, 81: 22, 82: 24, 83: 19, 84: 24, 85: 25, 86: 21, 87: 17, 88: 22, 89: 20, 90: 20, 91: 19, 92: 29, 93: 28, 94: 24, 95: 21, 96: 22, 97: 19, 98: 17, 99: 20}, 'goldilocks': {0: 12, 1: 8, 2: 3, 3: 11, 4: 21, 5: 11, 6: 10, 7: 19, 8: 5, 9: 2, 10: 10, 11: 6, 12: 2, 13: 2, 14: 12, 15: 15, 16: 15, 17: 1, 18: 2, 19: 7, 20: 12, 21: 1, 22: 18, 23: 10, 24: 18, 25: 1, 26: 5, 27: 2, 28: 7, 29: 18, 30: 4, 31: 3, 32: 20, 33: 15, 34: 2, 35: 24, 36: 13, 37: 11, 38: 15, 39: 17, 40: 4, 41: 18, 42: 21, 43: 2, 44: 6, 45: 10, 46: 17, 47: 8, 48: 2, 49: 11, 50: 7, 51: 13, 52: 5, 53: 20, 54: 17, 55: 13, 56: 3, 57: 5, 58: 20, 59: 7, 60: 2, 61: 3, 62: 5, 63: 3, 64: 1, 65: 8, 66: 2, 67: 15, 68: 2, 69: 5, 70: 4, 71: 3, 72: 3, 73: 22, 74: 17, 75: 16, 76: 4, 77: 2, 78: 7, 79: 3, 80: 1, 81: 2, 82: 10, 83: 6, 84: 10, 85: 1, 86: 1, 87: 14, 88: 4, 89: 4, 90: 7, 91: 7, 92: 3, 93: 8, 94: 9, 95: 4, 96: 12, 97: 6, 98: 17, 99: 8}, 'title': 'Actions'}
# MW
m_errors = {'immediate': 0, 'informed': 28, 'regression': 0, 'goldilocks': 0}
m_fuel = {'title': 'Fuel Consumed', 'immediate': {0: 10.96, 1: 5.099999999999999, 2: 14.91, 3: 3.09, 4: -0.9299999999999997, 5: 2.99, 6: 8.82, 7: 8.7, 8: 10.9, 9: 8.6, 10: 0.03999999999999915, 11: 8.78, 12: 12.04, 13: 8.899999999999999, 14: 12.360000000000001, 15: 7.01, 16: 1.1600000000000001, 17: 18.390000000000004, 18: 11.989999999999998, 19: 8.77, 20: -1.0, 21: 1.9499999999999993, 22: 9.31, 23: 14.2, 24: 0.0, 25: 8.74, 26: 9.0, 27: -1.9700000000000006, 28: 17.740000000000002, 29: 17.14, 30: 9.0, 31: 4.220000000000001, 32: 6.0, 33: -0.08999999999999986, 34: -0.05000000000000071, 35: 11.920000000000002, 36: 1.129999999999999, 37: 14.019999999999996, 38: 4.890000000000001, 39: 8.889999999999999, 40: 8.71, 41: 5.1, 42: 2.01, 43: 8.44, 44: 9.77, 45: 8.82, 46: 11.41, 47: -0.17999999999999972, 48: 10.190000000000001, 49: 8.75, 50: 8.94, 51: -1.0999999999999996, 52: -2.0600000000000005, 53: -0.120000000000001, 54: 6.21, 55: 5.200000000000001, 56: 5.16, 57: 1.8399999999999999, 58: -2.039999999999999, 59: 8.99, 60: 15.030000000000001, 61: 6.98, 62: 4.0600000000000005, 63: 3.1500000000000004, 64: 4.24, 65: 10.9, 66: 9.93, 67: 9.01, 68: 1.0099999999999998, 69: 9.91, 70: 13.02, 71: 1.9499999999999993, 72: -0.10999999999999943, 73: 17.99, 74: 9.959999999999999, 75: -1.9600000000000009, 76: 6.99, 77: 0.120000000000001, 78: -2.0, 79: 5.14, 80: 6.09, 81: 8.9, 82: 0.08000000000000007, 83: 17.830000000000002, 84: 5.75, 85: 16.39, 86: 8.75, 87: 1.8200000000000003, 88: 3.9299999999999997, 89: 0.9600000000000009, 90: 5.87, 91: 9.020000000000001, 92: -0.9400000000000013, 93: 12.25, 94: 5.0, 95: 2.05, 96: 0.19000000000000128, 97: 8.79, 98: -1.0899999999999999, 99: -1.9100000000000001}, 'informed': {0: 3.29, 1: 17.200000000000003, 2: 20.47, 3: 2.17, 4: 8.99, 5: 6.159999999999999, 6: 6.42, 7: 8.73, 8: 7.359999999999999, 9: 3.92, 10: 1.83, 11: 2.8899999999999997, 12: 1.9600000000000009, 13: 6.99, 14: 7.65, 15: 7.3, 16: 1.1500000000000004, 17: 21.009999999999998, 18: 8.809999999999999, 19: 2.0300000000000002, 20: 10.28, 21: -2.0199999999999996, 22: 7.15, 23: 17.55, 24: 8.14, 25: 8.129999999999999, 26: 1.0700000000000003, 27: 16.69, 28: 13.399999999999999, 29: 4.99, 30: 5.62, 31: -0.009999999999999787, 32: 29.42, 33: 18.129999999999995, 34: 17.650000000000002, 35: 8.29, 36: 3.0, 37: 16.240000000000002, 38: 8.76, 39: 8.139999999999999, 40: 13.45, 41: 8.9, 42: 8.06, 43: 6.5600000000000005, 44: 7.25, 45: 4.6, 46: 2.17, 47: 12.3, 48: 8.45, 49: 7.779999999999999, 50: 2.12, 51: 8.78, 52: 14.95, 53: 6.37, 54: 15.249999999999998, 55: 20.43, 56: 17.9, 57: 14.209999999999999, 58: 5.83, 59: 8.69, 60: 4.01, 61: 8.85, 62: 5.77, 63: 4.12, 64: 14.16, 65: 8.27, 66: 8.280000000000001, 67: 7.620000000000001, 68: 4.0600000000000005, 69: 3.29, 70: 5.0, 71: 6.970000000000001, 72: 4.88, 73: 1.0600000000000005, 74: 19.859999999999996, 75: 19.199999999999996, 76: 8.629999999999999, 77: -2.039999999999999, 78: 9.28, 79: 15.7, 80: 17.68, 81: 1.3599999999999994, 82: 8.030000000000001, 83: 3.01, 84: 8.69, 85: 0.9700000000000006, 86: 4.970000000000001, 87: 17.33, 88: 5.14, 89: 2.01, 90: 16.58, 91: 8.64, 92: 8.870000000000001, 93: 13.599999999999998, 94: 14.32, 95: 3.8, 96: 3.83, 97: 8.25, 98: 3.1500000000000004, 99: 7.8}, 'regression': {0: 5.81, 1: -0.2699999999999996, 2: 21.409999999999997, 3: 8.83, 4: 12.140000000000002, 5: 26.990000000000002, 6: 14.09, 7: 5.8, 8: 3.0700000000000003, 9: 2.66, 10: 10.9, 11: 8.71, 12: 10.11, 13: 11.879999999999999, 14: 10.100000000000001, 15: 9.959999999999999, 16: 2.91, 17: 8.89, 18: 5.92, 19: 6.08, 20: 6.02, 21: 6.0600000000000005, 22: 5.89, 23: 14.85, 24: 5.9, 25: 8.82, 26: 8.850000000000001, 27: 9.98, 28: 11.270000000000001, 29: 11.870000000000001, 30: 7.940000000000001, 31: 6.0600000000000005, 32: 8.85, 33: 3.0700000000000003, 34: 5.88, 35: 0.0, 36: 6.32, 37: 9.059999999999999, 38: 11.15, 39: 8.68, 40: 19.27, 41: 8.75, 42: 11.170000000000002, 43: 8.850000000000001, 44: 13.94, 45: 8.02, 46: 8.64, 47: 17.73, 48: 23.019999999999996, 49: 8.84, 50: 12.03, 51: 9.24, 52: 14.100000000000001, 53: 3.13, 54: 12.180000000000003, 55: 22.430000000000003, 56: 5.93, 57: 12.15, 58: 8.79, 59: 17.2, 60: 6.08, 61: 12.14, 62: 8.709999999999999, 63: 18.05, 64: 5.91, 65: 5.65, 66: 5.8, 67: 6.15, 68: 7.220000000000001, 69: 20.110000000000007, 70: 18.11, 71: 8.86, 72: 6.04, 73: 21.009999999999998, 74: 6.259999999999998, 75: 6.07, 76: 2.87, 77: 7.890000000000001, 78: 8.879999999999999, 79: 8.58, 80: 6.0600000000000005, 81: 5.890000000000001, 82: 5.9399999999999995, 83: 5.93, 84: 8.61, 85: 13.969999999999999, 86: 10.070000000000002, 87: 8.870000000000001, 88: 3.08, 89: 5.96, 90: 8.3, 91: 8.85, 92: 11.990000000000002, 93: 3.3200000000000003, 94: 2.83, 95: 5.84, 96: 13.08, 97: 8.01, 98: 6.04, 99: 5.92}, 'goldilocks': {0: 5.25, 1: 12.9, 2: 2.1100000000000003, 3: 6.0200000000000005, 4: 8.98, 5: 6.16, 6: 2.09, 7: -1.1099999999999994, 8: 8.149999999999999, 9: 2.09, 10: 8.69, 11: -0.9199999999999999, 12: 8.82, 13: -2.039999999999999, 14: 7.25, 15: 0.009999999999999787, 16: 8.79, 17: 3.7699999999999996, 18: 5.7, 19: 5.15, 20: 12.200000000000001, 21: 8.540000000000001, 22: -1.08, 23: 14.979999999999999, 24: 7.75, 25: 11.040000000000001, 26: 9.01, 27: 4.08, 28: 3.12, 29: 5.14, 30: 8.870000000000001, 31: 2.84, 32: 6.720000000000001, 33: 7.15, 34: 1.9000000000000004, 35: 6.13, 36: 5.040000000000001, 37: 7.07, 38: -0.870000000000001, 39: 4.109999999999999, 40: 0.0, 41: 6.779999999999999, 42: 8.780000000000001, 43: 13.759999999999998, 44: -1.1099999999999994, 45: 8.879999999999999, 46: 11.32, 47: 7.970000000000001, 48: 10.04, 49: 7.95, 50: 2.26, 51: -0.030000000000001137, 52: -1.0, 53: 8.870000000000001, 54: 2.0599999999999996, 55: 4.84, 56: 8.73, 57: 11.19, 58: 8.92, 59: 8.99, 60: 7.05, 61: 1.120000000000001, 62: -0.9900000000000002, 63: 10.230000000000002, 64: -2.0500000000000007, 65: 13.06, 66: 3.1500000000000004, 67: 12.86, 68: 9.280000000000001, 69: 1.9499999999999993, 70: 8.629999999999999, 71: 2.0300000000000002, 72: 9.16, 73: -2.0999999999999996, 74: 8.67, 75: 5.89, 76: 8.94, 77: 8.860000000000001, 78: 7.1899999999999995, 79: 2.04, 80: 5.890000000000001, 81: 8.19, 82: 6.2, 83: 8.870000000000001, 84: 2.1399999999999997, 85: 8.91, 86: 2.0300000000000002, 87: 8.879999999999999, 88: 9.86, 89: 2.8600000000000003, 90: 16.29, 91: 17.84, 92: 10.29, 93: 8.71, 94: 6.0, 95: 11.77, 96: -0.08000000000000007, 97: 8.770000000000001, 98: 8.899999999999999, 99: 0.009999999999999787}}
m_actions = {'immediate': {0: 15, 1: 8, 2: 19, 3: 7, 4: 2, 5: 4, 6: 11, 7: 11, 8: 14, 9: 10, 10: 3, 11: 10, 12: 16, 13: 10, 14: 18, 15: 12, 16: 4, 17: 23, 18: 15, 19: 10, 20: 2, 21: 6, 22: 10, 23: 20, 24: 3, 25: 11, 26: 13, 27: 1, 28: 21, 29: 20, 30: 10, 31: 8, 32: 10, 33: 4, 34: 3, 35: 15, 36: 5, 37: 19, 38: 8, 39: 11, 40: 10, 41: 6, 42: 5, 43: 9, 44: 15, 45: 11, 46: 15, 47: 3, 48: 15, 49: 11, 50: 11, 51: 2, 52: 2, 53: 3, 54: 7, 55: 10, 56: 6, 57: 5, 58: 1, 59: 15, 60: 17, 61: 8, 62: 7, 63: 6, 64: 7, 65: 13, 66: 12, 67: 10, 68: 5, 69: 12, 70: 15, 71: 5, 72: 3, 73: 21, 74: 12, 75: 1, 76: 8, 77: 3, 78: 1, 79: 8, 80: 7, 81: 10, 82: 4, 83: 21, 84: 10, 85: 19, 86: 12, 87: 5, 88: 7, 89: 4, 90: 7, 91: 11, 92: 2, 93: 17, 94: 6, 95: 5, 96: 3, 97: 11, 98: 2, 99: 1}, 'informed': {0: 8, 1: 15, 2: 11, 3: 3, 4: 2, 5: 11, 6: 6, 7: 10, 8: 9, 9: 6, 10: 8, 11: 4, 12: 2, 13: 9, 14: 7, 15: 10, 16: 5, 17: 26, 18: 8, 19: 4, 20: 16, 21: 2, 22: 5, 23: 14, 24: 5, 25: 13, 26: 8, 27: 17, 28: 15, 29: 7, 30: 3, 31: 4, 32: 35, 33: 22, 34: 18, 35: 3, 36: 4, 37: 17, 38: 10, 39: 10, 40: 14, 41: 11, 42: 10, 43: 10, 44: 2, 45: 8, 46: 3, 47: 12, 48: 6, 49: 6, 50: 2, 51: 10, 52: 11, 53: 3, 54: 19, 55: 12, 56: 11, 57: 20, 58: 6, 59: 8, 60: 8, 61: 10, 62: 5, 63: 4, 64: 11, 65: 6, 66: 11, 67: 2, 68: 10, 69: 8, 70: 9, 71: 6, 72: 3, 73: 10, 74: 24, 75: 27, 76: 10, 77: 2, 78: 11, 79: 13, 80: 22, 81: 8, 82: 6, 83: 9, 84: 2, 85: 5, 86: 11, 87: 12, 88: 6, 89: 9, 90: 14, 91: 10, 92: 12, 93: 18, 94: 12, 95: 3, 96: 3, 97: 2, 98: 4, 99: 9}, 'regression': {0: 9, 1: 9, 2: 26, 3: 10, 4: 21, 5: 31, 6: 21, 7: 10, 8: 10, 9: 10, 10: 15, 11: 9, 12: 13, 13: 14, 14: 15, 15: 12, 16: 9, 17: 10, 18: 9, 19: 9, 20: 11, 21: 9, 22: 9, 23: 20, 24: 10, 25: 9, 26: 9, 27: 15, 28: 13, 29: 18, 30: 9, 31: 10, 32: 9, 33: 10, 34: 9, 35: 10, 36: 10, 37: 11, 38: 13, 39: 9, 40: 23, 41: 9, 42: 14, 43: 10, 44: 16, 45: 10, 46: 10, 47: 20, 48: 28, 49: 10, 50: 21, 51: 14, 52: 16, 53: 10, 54: 20, 55: 27, 56: 9, 57: 18, 58: 11, 59: 20, 60: 9, 61: 15, 62: 10, 63: 22, 64: 10, 65: 11, 66: 9, 67: 10, 68: 9, 69: 24, 70: 20, 71: 9, 72: 9, 73: 25, 74: 10, 75: 10, 76: 9, 77: 10, 78: 11, 79: 10, 80: 9, 81: 9, 82: 9, 83: 10, 84: 10, 85: 17, 86: 12, 87: 9, 88: 9, 89: 10, 90: 9, 91: 9, 92: 21, 93: 10, 94: 9, 95: 10, 96: 15, 97: 10, 98: 10, 99: 9}, 'goldilocks': {0: 6, 1: 15, 2: 5, 3: 9, 4: 9, 5: 7, 6: 5, 7: 3, 8: 13, 9: 5, 10: 9, 11: 2, 12: 10, 13: 1, 14: 8, 15: 3, 16: 10, 17: 7, 18: 9, 19: 6, 20: 16, 21: 9, 22: 2, 23: 21, 24: 9, 25: 15, 26: 10, 27: 8, 28: 6, 29: 9, 30: 10, 31: 4, 32: 8, 33: 9, 34: 5, 35: 9, 36: 9, 37: 12, 38: 2, 39: 7, 40: 3, 41: 8, 42: 10, 43: 20, 44: 2, 45: 10, 46: 13, 47: 9, 48: 12, 49: 9, 50: 6, 51: 3, 52: 2, 53: 9, 54: 6, 55: 9, 56: 10, 57: 14, 58: 11, 59: 13, 60: 8, 61: 4, 62: 2, 63: 14, 64: 1, 65: 15, 66: 6, 67: 17, 68: 15, 69: 5, 70: 9, 71: 3, 72: 11, 73: 1, 74: 9, 75: 7, 76: 11, 77: 10, 78: 12, 79: 5, 80: 9, 81: 9, 82: 7, 83: 10, 84: 5, 85: 10, 86: 6, 87: 9, 88: 12, 89: 6, 90: 19, 91: 21, 92: 12, 93: 9, 94: 7, 95: 14, 96: 3, 97: 9, 98: 10, 99: 4}, 'title': 'Fuel Consumed'}plot([b_errors, b_actions, b_mass], use_base=False)
# plot([m_errors, m_actions, m_fuel], use_base=False)
expectation_types = ['immediate', 'informed', 'regression', 'goldilocks']
